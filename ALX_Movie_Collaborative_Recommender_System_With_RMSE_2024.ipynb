{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pHlYiFrzbH5",
    "outputId": "8b62d479-5a91-4457-cd7e-9d5fbc0c8c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading alx-movie-recommendation-project-2024, 250788671 bytes compressed\n",
      "[==================================================] 250788671 bytes downloaded\n",
      "Downloaded and uncompressed: alx-movie-recommendation-project-2024\n",
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'alx-movie-recommendation-project-2024:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F81285%2F8778365%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240621%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240621T225431Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3a20b6a60d79249249102eb9857593f5af5a06e3121c8f02e372f6c76c869cb9d3afd0745ebb7597914ab500ab82ae8545709850945bd5042caa0737c0fe68c3a02315a899e14e44f33bb559f4d7ac7e2e9e75b84a11e9ea3e461530b43838e201e68e58336b48979facf5c9c004cd73c2639dee0ebbedbcb195ebfd8a3d95276e4b3046cec206d382e742e087f56b0d19badbfd2484747bcb50ca1e13dd03a55d1eee6bbd9d80c876f784b6a98eb80d24706266de6b3a61dbb6ed410756e77f05d14325b334846a72ef9aa891f40160a30190d164f8339cc8e132f3a36df48244119de42cbff7e4e7d4e38c160ac7578b863b78c7e9c899182d21c249adfb8b'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T20:44:58.167253Z",
     "iopub.status.busy": "2024-06-16T20:44:58.166872Z",
     "iopub.status.idle": "2024-06-16T20:44:59.430137Z",
     "shell.execute_reply": "2024-06-16T20:44:59.428874Z",
     "shell.execute_reply.started": "2024-06-16T20:44:58.167222Z"
    },
    "id": "zLm29jEbzbIA",
    "outputId": "aabd0cbc-355b-447d-d01f-d6ef1d3cfa46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/alx-movie-recommendation-project-2024/train.csv\n",
      "/kaggle/input/alx-movie-recommendation-project-2024/movies.csv\n",
      "/kaggle/input/alx-movie-recommendation-project-2024/genome_tags.csv\n",
      "/kaggle/input/alx-movie-recommendation-project-2024/genome_scores.csv\n",
      "/kaggle/input/alx-movie-recommendation-project-2024/sample_submission.csv\n",
      "/kaggle/input/alx-movie-recommendation-project-2024/tags.csv\n",
      "/kaggle/input/alx-movie-recommendation-project-2024/imdb_data.csv\n",
      "/kaggle/input/alx-movie-recommendation-project-2024/links.csv\n",
      "/kaggle/input/alx-movie-recommendation-project-2024/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sB0YusUazbIB"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/test.csv')\n",
    "submission_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/sample_submission.csv')\n",
    "links_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/links.csv')\n",
    "tags_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/tags.csv')\n",
    "movies_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/movies.csv')\n",
    "genome_scores_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/genome_scores.csv')\n",
    "genome_tags_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/genome_tags.csv')\n",
    "imdb_data_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/imdb_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbGKIajk3KtU",
    "outputId": "7caaa9e9-b9e3-4ad3-a90c-7eb156b691bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   userId  movieId  rating   timestamp\n",
      "0    5163    57669     4.0  1518349992\n",
      "1  106343        5     4.5  1206238739\n",
      "2  146790     5459     5.0  1076215539\n",
      "3  106362    32296     2.0  1423042565\n",
      "4    9041      366     3.0   833375837\n",
      "   userId  movieId\n",
      "0       1     2011\n",
      "1       1     4144\n",
      "2       1     5767\n",
      "3       1     6711\n",
      "4       1     7318\n"
     ]
    }
   ],
   "source": [
    "print(movies_df.head())\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "stES61LD3koc",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b92ff9e7-e81b-4072-bb80-21fba449647a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: \n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "************\n",
      "Test: \n",
      "userId     0\n",
      "movieId    0\n",
      "dtype: int64\n",
      "************\n",
      "Movies: \n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n",
      "************\n",
      "Links: \n",
      "movieId      0\n",
      "imdbId       0\n",
      "tmdbId     107\n",
      "dtype: int64\n",
      "************\n",
      "IMDB: \n",
      "movieId              0\n",
      "title_cast       10068\n",
      "director          9874\n",
      "runtime          12089\n",
      "budget           19372\n",
      "plot_keywords    11078\n",
      "dtype: int64\n",
      "************\n",
      "Genome scores: \n",
      "movieId      0\n",
      "tagId        0\n",
      "relevance    0\n",
      "dtype: int64\n",
      "************\n",
      "Genome tags: \n",
      "tagId    0\n",
      "tag      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \")\n",
    "print(str(train_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Test: \")\n",
    "print(str(test_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Movies: \")\n",
    "print(str(movies_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Links: \")\n",
    "print(str(links_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"IMDB: \")\n",
    "print(str(imdb_data_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Genome scores: \")\n",
    "print(str(genome_scores_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Genome tags: \")\n",
    "print(str(genome_tags_df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hThmPkyP5T-7",
    "outputId": "a4a3b398-b7bd-4bbb-fa06-d1d1238b79d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357241 sha256=fab5a6c3615c0108073c207c34a91cd5405e6ac014918319477a1a0e587ebe5b\n",
      "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4OO6IJK55Rt"
   },
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lJ5tfGA6Q1U"
   },
   "outputs": [],
   "source": [
    "# train_df\n",
    "#reader = Reader(rating_scale=(1,5))\n",
    "#train_data = Dataset.load_from_df(train_df[['userId','movieId','rating']],reader)\n",
    "#trainset = train_data.build_full_trainset()\n",
    "\n",
    "#ORIGINAL CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocO8Hyomvfow"
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "train_data = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], reader)\n",
    "val_data = Dataset.load_from_df(val_data[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "trainset = train_data.build_full_trainset()\n",
    "valset = val_data.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJguvc_i8PfI",
    "outputId": "6175f374-1dd1-42f0-e4d4-45fa78236e51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f12cf6b7f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# test_user_predict_pairs = list(zip(test_df['userId'],test_df['movieId']))\n",
    "# test_predict = [svd.predict(uid,mid).est\n",
    "# for uid,mid in test_user_predict_pairs]\n",
    "\n",
    "# test_df['predicted_rating'] = test_predict\n",
    "# print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-xqiJMgwa4s",
    "outputId": "fb6c82c8-0f2d-4ace-affc-3d586629100f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8343\n",
      "MAE:  0.6332\n",
      "MSE: 0.6960\n",
      "RMSE: 0.8342516210254515\n",
      "MAE: 0.6331835071219826\n",
      "MSE: 0.6959757671835936\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for validation set\n",
    "predictions = svd.test(valset)\n",
    "\n",
    "# Calculate RMSE for the validation set\n",
    "rmse = accuracy.rmse(predictions)\n",
    "# Calculate MAE for the validation set\n",
    "mae = accuracy.mae(predictions)\n",
    "# Calculate MSE for the validation set\n",
    "mse = accuracy.mse(predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-pU9OpOBvHU"
   },
   "outputs": [],
   "source": [
    "#def predict_ratings(test_df,model):\n",
    "  #predictions= []\n",
    "  #for row in test_df.itertuples():\n",
    "    #user_id = row.userId\n",
    "    #movie_id = row.movieId\n",
    "    #prediction = model.predict(user_id,movie_id).est\n",
    "    #predictions.append((user_id,movie_id,prediction))\n",
    "    #predictions_df = pd.DataFrame(predictions,columns=['user_id','movie_id','predict_ratings'])\n",
    "  #return predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zz21bq-BAs27"
   },
   "outputs": [],
   "source": [
    "\n",
    "#test_subset= test_df.sample(n=1000)\n",
    "#predictions_df = predict_ratings(test_subset,svd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Svs1mhnJdVGA"
   },
   "outputs": [],
   "source": [
    "#predictions_df = predict_ratings(test_df, svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgx07bQl0RAe",
    "outputId": "77dc0225-aebc-4902-d2d5-672d2fcd2c48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ratings: 100%|██████████| 5000019/5000019 [00:27<00:00, 183958.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def predict_ratings(test_df, model):\n",
    "    predictions = []\n",
    "    # Wrap the iteration with tqdm to show the progress bar\n",
    "    for row in tqdm(test_df.itertuples(), total=len(test_df), desc=\"Predicting ratings\"):\n",
    "        user_id = row.userId\n",
    "        movie_id = row.movieId\n",
    "        prediction = model.predict(user_id, movie_id).est\n",
    "        predictions.append((user_id, movie_id, prediction))\n",
    "    # Create the DataFrame outside the loop to avoid repeated reassignments\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['user_id', 'movie_id', 'predicted_rating'])\n",
    "    return predictions_df\n",
    "\n",
    "\n",
    "#test_subset= test_df.sample(n=1000)\n",
    "#predictions_df = predict_ratings(test_subset,svd)\n",
    "\n",
    "# Assuming test_df and svd are already defined\n",
    "predictions_df = predict_ratings(test_df, svd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ybi-0rk4JZvW",
    "outputId": "12766f35-9cfa-495e-b8e0-4ed46e37028f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id    rating\n",
      "0  1_2011  3.371827\n",
      "1  1_4144  4.090105\n",
      "2  1_5767  3.572697\n",
      "3  1_6711  4.257370\n",
      "4  1_7318  2.748647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions_df['Id'] = predictions_df['user_id'].astype(str) + '_' + predictions_df['movie_id'].astype(str)\n",
    "predictions_df['rating'] = predictions_df['predicted_rating']\n",
    "predictions_df = predictions_df.drop(['user_id', 'movie_id', 'predicted_rating'], axis=1)\n",
    "predictions_df.to_csv('1_Submission.csv', index=False)\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6Uv1PW_hM9Kx",
    "outputId": "7da41b41-ac20-4eff-d7f7-d958de9d2fd6"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e406b7f1-890c-4799-b2b6-389963ec40ee\", \"1_Submission.csv\", 148305990)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('1_Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xr5UbBBE5Rkx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8778365,
     "sourceId": 81285,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
